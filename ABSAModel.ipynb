{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import nltk\n",
    "import xml.etree.ElementTree as et\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning, XML To DataFrame Conversion\n",
    "\n",
    "The training XML file has missing values for 'category' and 'polarity' fields as the Opinion element doesn't exists. This is handled by explicity adding Opinion Element. It it populated with NO_ASPECT as Entity and Atrribute, and 'noaspect' as polarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PREPROCESSING\n",
    "\n",
    "def preprocess_xml(xml_to_process, output_xml):\n",
    "    # Read and format XML for missing values\n",
    "\n",
    "    tree = et.parse(xml_to_process)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Normalize the XML to have empty opinions where it doesn't exist\n",
    "    for sentence in root.iter('sentence'):\n",
    "        # Check if Opinions element exists, if not, add it\n",
    "        if not sentence.findall('Opinions'):\n",
    "            new_opinion = et.SubElement(sentence,'Opinions')\n",
    "            opinion_cat = et.Element('Opinion')\n",
    "            new_opinion.append(opinion_cat)\n",
    "            opinion_cat.set('category', 'NO_ASPECT#NO_ASPECT')\n",
    "            opinion_cat.set('polarity', 'noaspect')\n",
    "\n",
    "    tree.write(output_xml, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read XML into a dataframe, save it in a csv\n",
    "\n",
    "def parse_xml_to_df(xml):\n",
    "    # Read xml and get the root\n",
    "    tree = et.parse(xml)\n",
    "    root = tree.getroot()\n",
    "    # create an empty list to store the data\n",
    "    data = []\n",
    "    # iterate over the elements in the XML file\n",
    "    for review in root:\n",
    "        # get review id\n",
    "        review_id = review.attrib\n",
    "        # create an empty dictionary to store the element's data\n",
    "        elem_dict = {}\n",
    "        # iterate over the sentences and add the sentence and opinion to the dictionary\n",
    "        for sentences in review[0]:\n",
    "            # get the review id, sentence id\n",
    "            elem_dict.update(review_id)\n",
    "            elem_dict['id'] = (sentences.attrib['id'])\n",
    "            # get the sentence text\n",
    "            elem_dict['sent_text'] = sentences[0].text\n",
    "            # Add Entity#Attribute pair along with polarity\n",
    "            for opinion in sentences[1]:\n",
    "                row_dict = {}\n",
    "                # Add review id, sentence id, and the sentence to the row\n",
    "                row_dict.update(elem_dict)\n",
    "                # Read and add the entity-attribute pair, polarity to the row\n",
    "                entityAttrib = opinion.attrib\n",
    "                row_dict.update(entityAttrib)\n",
    "                # We create unique row for each Entity#Attribute pair of a sentence\n",
    "                data.append(row_dict)\n",
    "\n",
    "    # create a pandas DataFrame from the data\n",
    "    df = pd.DataFrame(data)\n",
    "    # Reordering columns of dataframe for better readability\n",
    "    df = df[['rid', 'id', 'sent_text', 'category', 'polarity']]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structuring Dataframe for Training\n",
    "\n",
    "The function get_training_df() takes in the dataframe with parsed xml data as input.\n",
    "Based on the flags set, the function will return a dataframe with one-hot encoding of different classes that can be used for training the classifiers.\n",
    "\n",
    "To train the entity-attribute classifier, the dataframe should have sent_text and all unique entity-attribute class pairs one-hot encoded. The columns are - sent_text, NO_ASPECT#NO_ASPECT, LAPTOP#GENERAL,BATTERY#OPERATION_PERFORMANCE,... so on.\n",
    "\n",
    "To train the polarity classifier, dataframe with sent_text, one-hot encoded entity-attribute pairs, polarity is required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the dataframe and one-hot encode the classes\n",
    "\n",
    "# Create one-hot encoded dataframe with columns - sentence text, Entity#Attribute one-hot-encoded\n",
    "# ENTITY#ATTRIBUTE ONE-HOT ENCODED\n",
    "def get_training_df(df, classes, ea_flag = True, polarity_flag = False):\n",
    "    entity_labels = ['LAPTOP', 'DISPLAY', 'KEYBOARD', 'MOUSE', 'MOTHERBOARD', 'CPU', \n",
    "                     'FANS_COOLING', 'PORTS', 'MEMORY', 'POWER_SUPPLY', 'OPTICAL_DRIVES', \n",
    "                     'BATTERY', 'GRAPHICS', 'HARD_DISK', 'MULTIMEDIA_DEVICES', 'HARDWARE', \n",
    "                     'SOFTWARE', 'OS', 'WARRANTY', 'SHIPPING', 'SUPPORT', 'COMPANY']\n",
    "    attribute_labels = ['GENERAL', 'PRICE', 'QUALITY', 'DESIGN_FEATURES', \n",
    "                        'OPERATION_PERFORMANCE', 'USABILITY', 'PORTABILITY', \n",
    "                        'CONNECTIVITY', 'MISCELLANEOUS']\n",
    "\n",
    "    if(ea_flag == True):\n",
    "        # concatenate each possible combination of entity and attribute labels\n",
    "        entity_attribute_combinations = classes\n",
    "        #entity_attribute_combinations = [f'{entity}#{attribute}' for entity in entity_labels for attribute in attribute_labels]\n",
    "        np.append(entity_attribute_combinations,['NO_ASPECT#NO_ASPECT'])\n",
    "\n",
    "        # create a dictionary to map each entity-attribute combination to an index in the one-hot encoded vectors\n",
    "        aspect_map = {aspect: i for i, aspect in enumerate(entity_attribute_combinations)}\n",
    "\n",
    "        # load the data into a pandas DataFrame\n",
    "        ea_df = df[['sent_text','category','polarity']]\n",
    "\n",
    "        # add a new column for each possible combination of entity and attribute\n",
    "        for aspect_str in entity_attribute_combinations:\n",
    "            ea_df[aspect_str] = ea_df['category'].apply(lambda x: 1 if aspect_str==x else 0)\n",
    "\n",
    "        ea_df.drop('category', axis=1, inplace=True)\n",
    "        if(polarity_flag == True):\n",
    "            training_df = ea_df\n",
    "        else:\n",
    "            ea_df.drop('polarity', axis=1, inplace=True)\n",
    "            # We group the rows, so that for each sentence we have only one row\n",
    "            # with all E#A marked in it.\n",
    "            training_df = ea_df.groupby(ea_df['sent_text'], as_index=False).max().reindex(columns=ea_df.columns)\n",
    "        \n",
    "    else:\n",
    "        # ENTITY ONE-HOT ENCODED\n",
    "        # Used when entity and attributes are predicted seperately\n",
    "        entity_df = df[['sent_text', 'category']]\n",
    "        entity_df['category'] = [re.sub(r'(\\#)\\w*','', str(ea_pair)) for ea_pair in entity_df['category']]\n",
    "\n",
    "        # add a new column for each entity\n",
    "        for entity in entity_labels:\n",
    "            entity_df[entity] = entity_df['category'].apply(lambda x: 1 if entity==x else 0)\n",
    "\n",
    "        entity_df.drop('category', axis=1, inplace=True)\n",
    "        training_df = entity_df\n",
    "        training_df=entity_df.groupby(entity_df['sent_text'], as_index=False).max().reindex(columns=entity_df.columns)\n",
    "    \n",
    "    return training_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the textual data\n",
    "# Preprocessing the sentences\n",
    "# Data type to string, store in lower case, remove symbols, non-words, tokenize\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "def preprocess_text(sent_list) :\n",
    "    \n",
    "    # Convert all text to lower case\n",
    "    sent_list = [sent.lower() for sent in sent_list]\n",
    "    \n",
    "    # Remove Punctuation and non alpha-numeric characters\n",
    "    sent_list = [re.sub(r'[^\\w\\s]','', sent) for sent in sent_list]\n",
    "    \n",
    "    # Tokenization\n",
    "    sent_list = [nltk.word_tokenize(sent) for sent in sent_list]\n",
    "    \n",
    "    # Stop Word Removal\n",
    "    # Load the stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    for sent in sent_list:\n",
    "        for word in sent:\n",
    "            if word in stop_words:\n",
    "                sent.remove(word)\n",
    "        \n",
    "    # TO-DO: SpellCheck\n",
    "    \n",
    "    # Stemming/Lemmatization\n",
    "    load_model = spacy.load('en_core_web_sm', disable = ['parser','ner'])\n",
    "    for sent in sent_list :\n",
    "        sent = [word.lemma_ for word in load_model(str(sent))]\n",
    "    return sent_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mriya\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# TRAINING DATASET\n",
    "\n",
    "# Clean the training XML, and save the output\n",
    "preprocess_xml('Laptops_Train_p1.xml', 'training_p1_output.xml')\n",
    "\n",
    "# Parse the cleaned XML to create a dataframe with\n",
    "# columns - rid, id, sent_text, category, polarity\n",
    "xml_df = parse_xml_to_df('training_p1_output.xml')\n",
    "\n",
    "# Unique Entity-Attribute pairs to use for class encoding\n",
    "class_labels = xml_df['category'].unique()\n",
    "\n",
    "# Get training dataframe\n",
    "training_df = get_training_df(xml_df, class_labels, True)\n",
    "training_polarity_df = get_training_df(xml_df, class_labels, True, True)\n",
    "\n",
    "#User defined functions for text preprocessing\n",
    "#training_df.sent_text = preprocess_text(training_df.sent_text)\n",
    "\n",
    "# Save the dataframe with preprocessed text and one-hot encoding for E#A pairs, so you can directly load this and use it\n",
    "training_df.to_csv('TrainingData_ABSA_P1.csv')\n",
    "\n",
    "\n",
    "#TESTING DATASET\n",
    "\n",
    "# Perform similar operations on the testing gold dataset\n",
    "# Clean the training XML, and save the output\n",
    "preprocess_xml('Laptops_Test_p1_gold.xml', 'testing_p1_output.xml')\n",
    "\n",
    "# Parse the cleaned XML to create a dataframe with\n",
    "# columns - rid, id, sent_text, category, polarity\n",
    "xml_test_df = parse_xml_to_df('testing_p1_output.xml')\n",
    "\n",
    "# Get training dataframe\n",
    "testing_df = get_training_df(xml_test_df, class_labels, True)\n",
    "\n",
    "testing_polarity_df = get_training_df(xml_test_df, class_labels, True, True)\n",
    "\n",
    "# Save the dataframe with preprocessed text and one-hot encoding for E#A pairs, so you can directly load this and use it\n",
    "testing_df.to_csv('TestingData_ABSA_P1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Prediction Approach\n",
    "\n",
    "APPROACH 1  (Used)\n",
    "\n",
    "Step 1: Use vectorized sentence text to predict the combined Entity#Attribute Classes\n",
    "\n",
    "Step 2: Use vectorized sentence text and Entity#Attribute Classes to predict polarity of each Entity#Attribute pair.\n",
    "\n",
    "APPROACH 2  (Code added at the end)\n",
    "\n",
    "Step 1: Use vectorized sentence text to predict the Entity Classes\n",
    "\n",
    "Step 2: Use vectorized sentence text and Entity Classes to predict the Attribute Classes\n",
    "\n",
    "Step 3: Use vectorized sentence text, Entity Classes, Attribute Classes to predict polarity of each Aspect.\n",
    "\n",
    "\n",
    "Both the Approaches were tried. For Approach 1, neural network performed quite well, but simpler multilabel classifiers had a very poor performance.\n",
    "\n",
    "For Approach 2, Entity prediction using multilabel SVM gave really good results (0.7-0.8 accuracy). However, Attribute Prediction accuracy maxed at around 0.5-0.54 when tried with multiclass variants of Neural Network, SVM, Gaussian Naive-Bayes, Logistic Regression.\n",
    "\n",
    "Polarity prediction in both the approaches gave high accuracy when provided with correct aspects for the sentences. A simple multiclass SVM is implemented for that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical Vectorization of Textual Data\n",
    "\n",
    "Different Approaches were used to vectorize the text and convert to some numerical representation.\n",
    "\n",
    "scikit-learn library has built in classes like the Count Vectorizer (Bag-of-words), Tf-IDF Vectorizer. The performance with Count Vectorizer was much better and has been used in all the classifiers.\n",
    "\n",
    "A word2vec model was also trained and feature vectors were extracted from that but the classifier performance was poor compared to the classifier trained with Count Vectorizer features. (Sample Code for word2vec added at the end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING DATA for ENTITY-ATTRIBUTE PREDICTION\n",
    "# Vectorising and Splitting Training Data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Split the training data into train-test sets: x_train, y_train, x_test, y_test\n",
    "x_train_ea, x_test_ea, y_train_ea, y_test_ea = train_test_split(training_df['sent_text'],\n",
    "                                                    training_df.drop('sent_text', axis=1), \n",
    "                                                    test_size=0.1)\n",
    "\n",
    "# FEATURE VECTOR\n",
    "# Load CountVectorizer\n",
    "count_vect = CountVectorizer(max_df=1.0, stop_words='english', max_features=1000)\n",
    "\n",
    "# Vectorize the textual data\n",
    "x_train_ea = count_vect.fit_transform(x_train_ea)\n",
    "\n",
    "# x_test to be used for validation, and so we don't use fit_transform it\n",
    "x_test_ea = count_vect.transform(x_test_ea)\n",
    "\n",
    "y_train_arr = (y_train_ea.iloc[:,1:]).to_numpy()\n",
    "\n",
    "\n",
    "# GOLD TEST DATASET\n",
    "# We use the same count vectorizer object to transform the gold test data\n",
    "# so that we have similar sized feature matrix of X\n",
    "\n",
    "# Read the training data into X and Y\n",
    "x_test_predict = count_vect.transform(testing_df.sent_text)\n",
    "y_test_predict = testing_df.drop('sent_text', axis=1)\n",
    "\n",
    "y_ground_truth = (y_test_predict.iloc[:,1:]).to_numpy()\n",
    "\n",
    "# The feature vector sizes are different for training and test(validation) set\n",
    "# We apply padding to have same sized input feature vectors for both training and validating\n",
    "if x_test_predict.shape[1] < x_train_ea.shape[1]:\n",
    "    # Pad the test input features with zeros to match the number of columns in the training input features\n",
    "    padding = np.zeros((x_test_predict.shape[0], x_train_ea.shape[1] - x_test_predict.shape[1]))\n",
    "    x_test_predict = np.concatenate((x_test_predict, padding), axis=1)\n",
    "elif x_test_predict.shape[1] > x_train_ea.shape[1]:\n",
    "    # Truncate the test input features to match the number of columns in the training input features\n",
    "    x_test_predict = x_test_predict[:, :x_train_ea.shape[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENTITY-ATTRIBUTE Classifier\n",
    "\n",
    "A Neural Network model has been used as multilabel classifier to predict all possible classes for an input sentence/review.\n",
    "\n",
    "Other models like multilabel SVM, RandomForest, Multi-layer Perceptron were also tried but the accuracy on joint entity-attribute prediction was very low (20-40%). However, SVM performed quite well when used to predict just the entity (accuracy between 70-80% achieved)\n",
    "\n",
    "The Sequential Neural Network model is selected due to its small training time, good accuracy on training data, and similarly high accuracy on gold test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n",
      "Train on 2243 samples\n",
      "Epoch 1/10\n",
      "2243/2243 [==============================] - ETA: 5s - loss: 1.9000 - accuracy: 0.53 - ETA: 0s - loss: 1.3834 - accuracy: 0.79 - ETA: 0s - loss: 1.0780 - accuracy: 0.88 - 0s 93us/sample - loss: 0.9684 - accuracy: 0.9091\n",
      "Epoch 2/10\n",
      "2243/2243 [==============================] - ETA: 0s - loss: 0.4569 - accuracy: 0.98 - ETA: 0s - loss: 0.3650 - accuracy: 0.98 - ETA: 0s - loss: 0.3054 - accuracy: 0.98 - 0s 59us/sample - loss: 0.2832 - accuracy: 0.9856\n",
      "Epoch 3/10\n",
      "2243/2243 [==============================] - ETA: 0s - loss: 0.1793 - accuracy: 0.98 - ETA: 0s - loss: 0.1458 - accuracy: 0.98 - 0s 49us/sample - loss: 0.1260 - accuracy: 0.9856\n",
      "Epoch 4/10\n",
      "2243/2243 [==============================] - ETA: 0s - loss: 0.0945 - accuracy: 0.98 - ETA: 0s - loss: 0.0868 - accuracy: 0.98 - ETA: 0s - loss: 0.0827 - accuracy: 0.98 - 0s 51us/sample - loss: 0.0822 - accuracy: 0.9856\n",
      "Epoch 5/10\n",
      "2243/2243 [==============================] - ETA: 1s - loss: 0.0701 - accuracy: 0.98 - ETA: 0s - loss: 0.0690 - accuracy: 0.98 - 0s 59us/sample - loss: 0.0678 - accuracy: 0.9856\n",
      "Epoch 6/10\n",
      "2243/2243 [==============================] - ETA: 0s - loss: 0.0673 - accuracy: 0.98 - ETA: 0s - loss: 0.0638 - accuracy: 0.98 - ETA: 0s - loss: 0.0621 - accuracy: 0.98 - 0s 61us/sample - loss: 0.0622 - accuracy: 0.9856\n",
      "Epoch 7/10\n",
      "2243/2243 [==============================] - ETA: 0s - loss: 0.0559 - accuracy: 0.98 - ETA: 0s - loss: 0.0603 - accuracy: 0.98 - ETA: 0s - loss: 0.0596 - accuracy: 0.98 - 0s 60us/sample - loss: 0.0597 - accuracy: 0.9856\n",
      "Epoch 8/10\n",
      "2243/2243 [==============================] - ETA: 0s - loss: 0.0639 - accuracy: 0.98 - ETA: 0s - loss: 0.0593 - accuracy: 0.98 - ETA: 0s - loss: 0.0589 - accuracy: 0.98 - 0s 62us/sample - loss: 0.0585 - accuracy: 0.9856\n",
      "Epoch 9/10\n",
      "2243/2243 [==============================] - ETA: 0s - loss: 0.0519 - accuracy: 0.98 - ETA: 0s - loss: 0.0565 - accuracy: 0.98 - 0s 49us/sample - loss: 0.0578 - accuracy: 0.9856\n",
      "Epoch 10/10\n",
      "2243/2243 [==============================] - ETA: 0s - loss: 0.0605 - accuracy: 0.98 - ETA: 0s - loss: 0.0584 - accuracy: 0.98 - ETA: 0s - loss: 0.0578 - accuracy: 0.98 - 0s 60us/sample - loss: 0.0574 - accuracy: 0.9856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2132e9de390>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# create a neural network model\n",
    "entity_classifier = Sequential()\n",
    "entity_classifier.add(Dense(64, activation='relu', input_shape=(x_train_ea.shape[1],), kernel_regularizer=regularizers.l2(0.01)))\n",
    "#entity_classifier.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "entity_classifier.add(Dense(81, activation='sigmoid'))\n",
    "\n",
    "# compile the model\n",
    "entity_classifier.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# fit the model to the data\n",
    "entity_classifier.fit(x_train_ea, y_train_arr, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATION for ENTITY-ATTRIBUTE Classifier\n",
    "\n",
    "While the high accuracy on validation set might indicate overfitting, it is suprising to see that around about same accuracy is achieved on the Gold Test Dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n",
      "Validation Set\n",
      "Test loss: 0.056145722836256025\n",
      "Test accuracy: 0.9860247\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n",
      "Testing Gold Dataset\n",
      "Test loss: 0.06699925952998964\n",
      "Test accuracy: 0.983065\n"
     ]
    }
   ],
   "source": [
    "# Evaluate accuracy against the validation set\n",
    "y_test_arr = (y_test_ea.iloc[:,1:]).to_numpy()\n",
    "score_val = entity_classifier.evaluate(x_test_ea, y_test_arr, verbose=0)\n",
    "print('Validation Set\\nTest loss:', score_val[0])\n",
    "print('Test accuracy:', score_val[1])\n",
    "\n",
    "# Evaluate accuracy on the gold testing dataset\n",
    "\n",
    "predicted_labels = entity_classifier.predict(x_test_predict)\n",
    "score_gold_test = entity_classifier.evaluate(x_test_predict, y_ground_truth, verbose=0)\n",
    "\n",
    "print('Testing Gold Dataset\\nTest loss:', score_gold_test[0])\n",
    "print('Test accuracy:', score_gold_test[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polarity Prediction\n",
    "\n",
    "This is a multiclass classification problem. With only 4 classes to choose from, a simple model like SVC gives high accuracy and is fast too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1282\n",
      "1282\n"
     ]
    }
   ],
   "source": [
    "# POLARITY PREDICTION\n",
    "\n",
    "# TRAINING DATA\n",
    "\n",
    "polarity_pred_df = training_polarity_df\n",
    "#X = pd.concat([entity_df.reset_index(drop=True), attribute_encoded.reset_index(drop=True)], axis=1)\n",
    "\n",
    "polarity_labels = polarity_pred_df['polarity'].unique()\n",
    "polarity_labels_dict = {polarity_labels[i]: i for i in range(len(polarity_labels))}\n",
    "\n",
    "train_pol_vals = polarity_pred_df['polarity'].values\n",
    "Y_polarity_pred = np.array([polarity_labels_dict[label] for label in train_pol_vals])\n",
    "\n",
    "X_polarity_pred = polarity_pred_df.drop('polarity', axis=1)\n",
    "# Split the training data into train-test sets: x_train, y_train, x_test, y_test\n",
    "x_train_pol, x_test_pol, y_train_pol, y_test_pol = train_test_split(X_polarity_pred, Y_polarity_pred, test_size=0.1)\n",
    "\n",
    "# FEATURE VECTOR\n",
    "# Load CountVectorizer\n",
    "count_vectorizer = CountVectorizer(max_df=1.0,stop_words='english', max_features=1200)\n",
    "\n",
    "# Read the training data into X and Y\n",
    "x_feat = count_vectorizer.fit_transform(x_train_pol.sent_text)\n",
    "x_train_pol = x_train_pol.drop('sent_text', axis=1)\n",
    "x_train_pol = pd.concat([x_train_pol.reset_index(drop=True), \n",
    "                         pd.DataFrame(x_feat.todense()).reset_index(drop=True)], axis=1)\n",
    "x_train_pol = x_train_pol.reindex(columns=x_train_pol.columns)\n",
    "\n",
    "# x_test to be used for validation, and so we don't use fit_transform it\n",
    "x_test_feat = count_vectorizer.transform(x_test_pol.sent_text)\n",
    "x_test_pol = x_test_pol.drop('sent_text', axis=1)\n",
    "x_test_pol = pd.concat([x_test_pol.reset_index(drop=True),\n",
    "                    pd.DataFrame(x_test_feat.todense()).reset_index(drop=True)], axis=1)\n",
    "x_test_pol = x_test_pol.reindex(columns=x_test_pol.columns)\n",
    "\n",
    "print(x_train_pol.shape[1])\n",
    "print(x_test_pol.shape[1])\n",
    "if x_test_pol.shape[1] < x_train_pol.shape[1]:\n",
    "    # Pad the test input features with zeros to match the number of columns in the training input features\n",
    "    padding = np.zeros((x_test_pol.shape[0], x_train_pol.shape[1] - x_test_pol.shape[1]))\n",
    "    x_test_pol = np.concatenate((x_test_pol, padding), axis=1)\n",
    "elif x_test_pol.shape[1] > x_train_pol.shape[1]:\n",
    "    # Truncate the test input features to match the number of columns in the training input features\n",
    "    x_test_pol = x_test_pol[:, :x_train_pol.shape[1]]\n",
    "    \n",
    "# GOLD TEST DATASET\n",
    "\n",
    "x_pol_predict = testing_polarity_df.drop('polarity', axis=1)\n",
    "x_features = count_vectorizer.transform(x_pol_predict.sent_text)\n",
    "x_pol_predict = x_pol_predict.drop('sent_text', axis=1)\n",
    "x_pol_predict = pd.concat([x_pol_predict.reset_index(drop=True), \n",
    "                         pd.DataFrame(x_features.todense()).reset_index(drop=True)], axis=1)\n",
    "x_pol_predict = x_pol_predict.reindex(columns=x_pol_predict.columns)\n",
    "\n",
    "train_pol_vals = testing_polarity_df['polarity'].values\n",
    "y_pol_predict = np.array([polarity_labels_dict[label] for label in train_pol_vals])\n",
    "\n",
    "if x_pol_predict.shape[1] < x_train_pol.shape[1]:\n",
    "    # Pad the test input features with zeros to match the number of columns in the training input features\n",
    "    padding = np.zeros((x_pol_predict.shape[0], x_train_pol.shape[1] - x_pol_predict.shape[1]))\n",
    "    x_pol_predict = np.concatenate((x_pol_predict, padding), axis=1)\n",
    "elif x_pol_predict.shape[1] > x_train_pol.shape[1]:\n",
    "    # Truncate the test input features to match the number of columns in the training input features\n",
    "    x_pol_predict = x_pol_predict[:, :x_train_pol.shape[1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POLARITY CLASSIFIER\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "import pickle\n",
    "\n",
    "# create a multiclass SVM model\n",
    "clf_polarity = SVC(kernel='linear', C=1, decision_function_shape='ovr')\n",
    "\n",
    "# fit the model to the training data\n",
    "clf_polarity.fit(x_train_pol, y_train_pol)\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'polarityPredictionSVC.sav'\n",
    "pickle.dump(clf_polarity, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On validation set\n",
      "Accuracy: 0.8338278931750742\n",
      "F1 score: 0.8338278931750742\n",
      "On Gold Test Dataset\n",
      "Accuracy: 0.6803995006242197\n",
      "F1 score: 0.6803995006242197\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance of Polarity Classifier\n",
    "from sklearn.metrics import accuracy_score, f1_score   \n",
    "\n",
    "# Evaluate the performance of the model on validation set\n",
    "\n",
    "y_predictions = clf_polarity.predict(x_test_pol)\n",
    "acc_clf = accuracy_score(y_test_pol, y_predictions)\n",
    "f1_clf = f1_score(y_test_pol, y_predictions, average='micro')\n",
    "print('On validation set\\nAccuracy:', acc_clf)\n",
    "print('F1 score:', f1_clf)\n",
    "\n",
    "# Evaluate against Gold Test Dataset\n",
    "\n",
    "y_predict_gold = clf_polarity.predict(x_pol_predict)\n",
    "acc_clf_gold = accuracy_score(y_pol_predict, y_predict_gold)\n",
    "f1_clf_gold = f1_score(y_pol_predict, y_predict_gold, average='micro')\n",
    "print('On Gold Test Dataset\\nAccuracy:', acc_clf_gold)\n",
    "print('F1 score:', f1_clf_gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other models trained for ABSA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "#Load the preprocessed data (lowercased, stopwords removed, non-words removed, tokenized)\n",
    "#training_df['sent_text'] preprocessed in user defined functions\n",
    "\n",
    "#Train and save the word2vec model for laptop reviews\n",
    "model = Word2Vec(training_df.sent_text, size=100, window=5, min_count=1, workers=4)\n",
    "model.save(\"word2vec.model\")\n",
    "\n",
    "#Create feature vectors by summing up on word embeddings for each sentence\n",
    "\n",
    "model = Word2Vec.load(\"word2vec.model\")\n",
    "\n",
    "feature_vectors = []\n",
    "for sentence in grouped_df.sent_text:\n",
    "    embeddings = []\n",
    "    for word in sentence:\n",
    "        if word in model.wv.vocab:\n",
    "            embeddings.append(model.wv[word])\n",
    "    if len(embeddings) > 0:\n",
    "        feature_vectors.append(np.mean(embeddings, axis=0))\n",
    "    else:\n",
    "        feature_vectors.append(np.zeros(model.vector_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilabel Entity-Attribute Prediction"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Code for other classifiers that were tried to predict entity-attribute pairs jointly.\n",
    "\n",
    "#MULTILAYER PERCEPTRON\n",
    "#Build the multilable MLP Classifier for extracting all possible entity-attribute pairs\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_clf = MLPClassifier(verbose=True, random_state=1, max_iter=300)\n",
    "mlp_clf.fit(x_train, y_array)\n",
    "print(mlp_clf.n_iter_)\n",
    "\n",
    "#RANDOM FOREST\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(verbose=1, n_estimators=1000, random_state=0).fit(x_train, y_array)\n",
    "\n",
    "#BINARY RELEVANCE with GAUSSIAN NAIVE-BAYES\n",
    "using binary relevance\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#initialize binary relevance multi-label classifier with a gaussian naive bayes base classifier\n",
    "br_clf = BinaryRelevance(GaussianNB(),[True,True])\n",
    "br_clf.fit(x_train, y_array)\n",
    "\n",
    "\n",
    "#SUPPORT VECTOR MACHINES\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "#Create the SVM classifier with OvR strategy\n",
    "svm_clf = OneVsRestClassifier(SVC())\n",
    "\n",
    "#Define the hyperparameter grid to search over\n",
    "param_grid = {'estimator__C': [0.1, 1, 10],'estimator__kernel': ['linear', 'rbf']}\n",
    "\n",
    "#Use grid search to find the optimal hyperparameters\n",
    "svm_grid = GridSearchCV(svm_clf, param_grid, cv=3)\n",
    "svm_grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilabel SVM for Entity Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Sample Code of SVM Classifier implemented in Approach 2\n",
    "#PREDICTING ENTITY CLASS USING SUPPORT VECTOR MACHINES for MULTILABEL CLASSIFICATION\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "#Create the SVM classifier with OvR strategy\n",
    "svm_clf_entity = OneVsRestClassifier(SVC())\n",
    "\n",
    "#Define the hyperparameter grid to search over\n",
    "param_grid = {'estimator__C': [0.1, 1, 10],'estimator__kernel': ['linear', 'rbf']}\n",
    "\n",
    "#Use grid search to find the optimal hyperparameters\n",
    "svm_grid = GridSearchCV(svm_clf_entity, param_grid, cv=3)\n",
    "svm_grid.fit(x_train, y_array)\n",
    "\n",
    "#MAKE PREDICTIONS \n",
    "\n",
    "#Make predictions on the test set\n",
    "y_pred = svm_grid.predict(x_test)\n",
    "\n",
    "y_ground_truth = np.array((y_test.iloc[:,1:]).to_numpy())\n",
    "\n",
    "#Evaluate the performance of the model\n",
    "acc = accuracy_score(y_ground_truth, y_pred)\n",
    "f1 = f1_score(y_ground_truth, y_pred, average='micro')\n",
    "print('Accuracy:', acc)\n",
    "print('F1 score:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass Sequential NN Classifier for ATTRIBUTE Prediction"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Sample Code of the Attribute Classifier implemented in Approach 2\n",
    "\n",
    "#The text has to be vectorized and has to be converted to dense matrix. This is then combined with one-hot encoded entity matrix.\n",
    "\n",
    "#Training data would have X : sent_text, entity classes one-hot encoded (one class per row); Y: attribute class\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy import sparse\n",
    "\n",
    "#Read the training data into X and Y\n",
    "X = get_training_df(xml_df, False)\n",
    "attribute_pred_df = pd.read_csv(\"attribute_df.csv\")\n",
    "Y = attribute_pred_df.drop(['attribute','sent_text'], axis=1)\n",
    "\n",
    "#Split the training data into train-test sets: x_train, y_train, x_test, y_test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.1)\n",
    "\n",
    "#FEATURE VECTOR\n",
    "count_vect = CountVectorizer(max_df=1.0)\n",
    "\n",
    "#Fit transform the text data, concatenate the text feature vector with entity class matrix\n",
    "x_sent_features = count_vect.fit_transform(x_train.sent_text)\n",
    "x_train = x_train.drop('sent_text', axis=1)\n",
    "x_train = pd.concat([x_train.reset_index(drop=True), pd.DataFrame(x_sent_features.todense()).reset_index(drop=True)], axis=1)\n",
    "x_train = x_train.reindex(columns=x_train.columns)\n",
    "\n",
    "#x_test to be used for validation, and so we don't use fit_transform on it\n",
    "x_test_features = count_vect.transform(x_test.sent_text)\n",
    "x_test = x_test.drop('sent_text', axis=1)\n",
    "x_test = pd.concat([x_test.reset_index(drop=True), pd.DataFrame(x_test_features.todense()).reset_index(drop=True)], axis=1)\n",
    "x_test = x_test.reindex(columns=x_test.columns)\n",
    "\n",
    "#The feature vector sizes are different for training and test(validation) set\n",
    "#We apply padding to have same sized input feature vectors for both training and validating\n",
    "if x_test.shape[1] < x_train.shape[1]:\n",
    "    #Pad the test input features with zeros to match the number of columns in the training input features\n",
    "    padding = np.zeros((x_test.shape[0], x_train.shape[1] - x_test.shape[1]))\n",
    "    x_test = np.concatenate((x_test, padding), axis=1)\n",
    "elif x_test.shape[1] > x_train.shape[1]:\n",
    "    #Truncate the test input features to match the number of columns in the training input features\n",
    "    x_test = x_test[:, :x_train.shape[1]]\n",
    "\n",
    "y_train_array = (y_train.iloc[:,1:]).to_numpy()\n",
    "y_test_array = (y_test.iloc[:,1:]).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attribute Prediction"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#A number of classifiers like SVC, Logistic Regression, Naive-Bayes, NeuralNetwork were used. \n",
    "#SVC and Neural Network both give an accuracy of around 54%. We use Neural Net because of its smaller training time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "#create a neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(x_train.shape[1],)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "\n",
    "#compile the model\n",
    "model.compile(loss='categorical_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])\n",
    "\n",
    "#train the model\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model.fit(x_train.to_numpy(), y_train_array,batch_size=batch_size,epochs=epochs,verbose=0,\n",
    "                    validation_data=(x_test.to_numpy(), y_test_array))\n",
    "                    \n",
    "score = model.evaluate(x_test.to_numpy(), y_test_array, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "Test loss: 1.5242192946838695\n",
    "Test accuracy: 0.537092"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
